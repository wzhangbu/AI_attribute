{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary package and functions.\n",
    "Notice:\\\n",
    "Env: python 3.12.9\\\n",
    "conda create -n AI_property python=3.12.9\\\n",
    "conda init bash\\\n",
    "source ~/.bashrc \\\n",
    "conda activate AI_property\n",
    "\n",
    "conda install numpy pandas openpyxl openai boto3 -c conda-forge\n",
    "\n",
    "conda install -c conda-forge fsspec s3fs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/HO_AI_Property_Attribute_2025\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import time\n",
    "import sys\n",
    "from openai import OpenAI\n",
    "import read_data\n",
    "import GPT_model\n",
    "\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the sample data and question file\n",
    "The sample data is in the directory: 's3://pr-home-datascience/Projects/AdHoc/InternProjects/2025/2025_Summer_AI_Property_Attributes/property_list_NJ_sample.csv'\n",
    "\n",
    "The question file is in the directory: './question.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                address     city state   zip5  zip4 unit_number    county  \\\n",
      "0        340 HOBART AVE  ABSECON    NJ  08201  1127         NaN  ATLANTIC   \n",
      "1  244 PENNSYLVANIA AVE  ABSECON    NJ  08201  1219         NaN  ATLANTIC   \n",
      "2     319 E WYOMING AVE  ABSECON    NJ  08201  1711         NaN  ATLANTIC   \n",
      "3         312 SPRUCE ST  ABSECON    NJ  08201  1726         NaN  ATLANTIC   \n",
      "4     905 TRAYMORE PKWY  ABSECON    NJ  08201  1513         NaN  ATLANTIC   \n",
      "\n",
      "  fault_code status_code  delivery_bc      qpid   rundt Number_of_Baths  \\\n",
      "0        NaN      S80000  82011127404  84770770  202410               2   \n",
      "1        NaN      S80000  82011219448  84770874  202410               2   \n",
      "2        NaN      S80000  82011711199  84770989  202410               4   \n",
      "3        NaN      S80000  82011726120  84771105  202410               2   \n",
      "4        NaN      S80000  82011513054  84771453  202410             1.1   \n",
      "\n",
      "  Number_of_Bedrooms  \n",
      "0                  3  \n",
      "1                  3  \n",
      "2                  4  \n",
      "3                  4  \n",
      "4                  2  \n"
     ]
    }
   ],
   "source": [
    "# The sample data is the the S3 directory\n",
    "sample_path = 's3://pr-home-datascience/Projects/AdHoc/InternProjects/2025/2025_Summer_AI_Property_Attributes/property_list_NJ_sample.csv'\n",
    "\n",
    "# Use the class in read_data.py to load the sample data\n",
    "df_samples = read_data.DataReader(sample_path)\n",
    "df_samples.preview()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The promps for the GPT will be as follows:\n",
      "I will give you the locations, please help me analyze how many bathrooms and bedrooms they have.\n",
      "Please respond in format: 'Bedrooms: X, Bathrooms: Y.\n",
      "Can you estimate how many bedrooms and bathrooms are at \n",
      "\n",
      "The final questions for the GPT that will be recorded are:\n",
      "Can you estimate how many bedrooms and bathrooms are at 340 HOBART AVE, ABSECON, NJ, 08201-1127\n",
      "Can you estimate how many bedrooms and bathrooms are at 244 PENNSYLVANIA AVE, ABSECON, NJ, 08201-1219\n"
     ]
    }
   ],
   "source": [
    "# Load the question file \n",
    "# Load the question txt \n",
    "print('The promps for the GPT will be as follows:')\n",
    "with open('questions.txt', 'r', encoding='utf-8') as f:\n",
    "    questions = np.array(f.read().splitlines(), dtype=str)\n",
    "for line in questions:\n",
    "    print(line)\n",
    "\n",
    "\n",
    "# Load the address txt\n",
    "# address     city state   zip5  zip4\n",
    "df_samples.data[\"full_address\"] = df_samples.data[\"address\"] + \", \" + df_samples.data[\"city\"] + \", \" + df_samples.data[\"state\"] +\\\n",
    "                             \", \" + df_samples.data[\"zip5\"] + '-' + df_samples.data[\"zip4\"] \n",
    "                            \n",
    "\n",
    "\n",
    "print('\\nThe final questions for the GPT that will be recorded are:')\n",
    "\n",
    "df_samples.data['questions'] = questions[2] + df_samples.data[\"full_address\"]\n",
    "print(df_samples.data['questions'][0])\n",
    "print(df_samples.data['questions'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model from GPT_model.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Initialize OpenAI client with API key\\\n",
    "2: Initialize the bedroom/bathroom estimator with GPT-4.1 model\\\n",
    "3: Fill missing values in sample data with the string 'NaN'\\\n",
    "4: Send general input questions to GPT for the first two samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Added general input: 'I will give you the locations, please help me analyze how many bathrooms and bedrooms they have.'\n",
      "üìù Added general input: 'Please respond in format: 'Bedrooms: X, Bathrooms: Y.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client  = OpenAI(api_key = \"\")\n",
    "\n",
    "estimator = GPT_model.BedroomBathroomEstimator(client=client, model=\"gpt-4.1\")\n",
    "df_samples.data=df_samples.data.fillna('NaN')\n",
    "\n",
    "# input the general message\n",
    "for i in range(2):\n",
    "    estimator.general_input(questions[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the samples: first 1000 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Define the range of samples to estimate (from n_start to n)\\\n",
    "2: Run GPT estimation on the selected questions and qpids\\\n",
    "3: Print the first few rows of the GPT estimation result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is the loop 0\n",
      "Now is the loop 100\n",
      "Now is the loop 200\n",
      "Now is the loop 300\n",
      "Now is the loop 400\n",
      "Now is the loop 500\n",
      "Now is the loop 600\n",
      "Now is the loop 700\n",
      "Now is the loop 800\n",
      "Now is the loop 900\n",
      "                                            question  \\\n",
      "0  Can you estimate how many bedrooms and bathroo...   \n",
      "1  Can you estimate how many bedrooms and bathroo...   \n",
      "2  Can you estimate how many bedrooms and bathroo...   \n",
      "3  Can you estimate how many bedrooms and bathroo...   \n",
      "4  Can you estimate how many bedrooms and bathroo...   \n",
      "\n",
      "                                        gpt_response      qpid  bathrooms  \\\n",
      "0                         Bedrooms: 3, Bathrooms: 2.  84770770        2.0   \n",
      "1                         Bedrooms: 4, Bathrooms: 2.  84770874        2.0   \n",
      "2                         Bedrooms: 3, Bathrooms: 2.  84770989        2.0   \n",
      "3  I'm sorry, but I do not have direct access to ...  84771105        2.0   \n",
      "4                         Bedrooms: 3, Bathrooms: 2.  84771453        2.0   \n",
      "\n",
      "   bedrooms  tokens_used  time_seconds  \n",
      "0       3.0           88          0.57  \n",
      "1       4.0           90          0.57  \n",
      "2       3.0           89          0.95  \n",
      "3       3.0          158          1.67  \n",
      "4       3.0           88          0.74  \n"
     ]
    }
   ],
   "source": [
    "# test sample and input them into model\n",
    "n = 1000\n",
    "n_start = 0\n",
    "df_GPT = estimator.estimate_all(df_samples.data['questions'][n_start: n], df_samples.data['qpid'][n_start: n])\n",
    "\n",
    "print(df_GPT.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total tokes used are 114393.\n",
      "The total time used are 1322.08.\n",
      "There are 334 samples have the same bathroom number.\n",
      "The accuracy is 33.40%.\n",
      "There are 440 samples have the same bedroom number.\n",
      "The accuracy is 44.00%.\n",
      "There are 184 samples have the same both bathroom and bedroom number.\n",
      "The accuracy is 18.40%.\n"
     ]
    }
   ],
   "source": [
    "# Show the comsuming results\n",
    "print(f'The total tokes used are {np.sum(df_GPT['tokens_used'])}.')\n",
    "print(f'The total time used are {np.sum(df_GPT['time_seconds'])}.')\n",
    "\n",
    "# Next is to compare the results with the available information, \n",
    "# i.e. true bedroom/bathroom number\n",
    "acc_bed = []\n",
    "acc_bath = []\n",
    "acc_all = []\n",
    "for i in range(n):\n",
    "    # Match qpid between GPT output and original data\n",
    "    if df_GPT['qpid'][i] == df_samples.data['qpid'][i]:\n",
    "        pred_bed = df_GPT['bedrooms'][i]\n",
    "        pred_bath = df_GPT['bathrooms'][i]\n",
    "        true_bed = float(df_samples.data['Number_of_Bedrooms'][i] )\n",
    "        true_bath = float(df_samples.data['Number_of_Baths'][i])\n",
    "\n",
    "        # Check if predicted bedroom count is correc\n",
    "        if pred_bed == true_bed:\n",
    "            acc_bed.append({\n",
    "                'i': i,\n",
    "                'qpid': df_GPT['qpid'][i],\n",
    "                'Number_of_Bedrooms': true_bed\n",
    "            })\n",
    "\n",
    "        # Check if predicted bathroom count is correct\n",
    "        if pred_bath == true_bath:\n",
    "            acc_bath.append({\n",
    "                'i': i,\n",
    "                'qpid': df_GPT['qpid'][i],\n",
    "                'Number_of_Baths': true_bath\n",
    "            })\n",
    "\n",
    "        # Check if both are correct\n",
    "        if pred_bed == true_bed and pred_bath == true_bath:\n",
    "            acc_all.append({\n",
    "                'i': i,\n",
    "                'qpid': df_GPT['qpid'][i],\n",
    "                'Number_of_Bedrooms': true_bed,\n",
    "                'Number_of_Baths': true_bath\n",
    "            })\n",
    "\n",
    "names = ['bathroom', 'bedroom', 'both bathroom and bedroom']\n",
    "for acc, name in zip([acc_bath, acc_bed, acc_all], names):\n",
    "    print(f'There are {len(acc)} samples have the same {name} number.')\n",
    "    print(f'The accuracy is {len(acc)/n:.2%}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to csv file, the whole data and correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next is to output the datafram into the csv file\n",
    "def merge_predictions_with_samples(df_samples, df_GPT, same_results=None):\n",
    "    \"\"\"\n",
    "    Merge df_samples.data with GPT predictions from df_GPT\n",
    "    based on row index (i) of same_results. \n",
    "    If `same_results` is provided, only merge rows whose indices are listed in same_results['i'].\n",
    "    If `same_results` is None, merge all rows based on row index.\n",
    "\n",
    "    Args:\n",
    "        df_samples: Data container with `.data` attribute as a DataFrame (original sample data).\n",
    "        df_GPT: DataFrame with GPT outputs (must include 'qpid', 'bedrooms', 'bathrooms', etc.).\n",
    "        same_results: Optional list of dicts containing 'i' indices to subset matching rows.\n",
    "\n",
    "    Output: includes all columns from df_samples, and adds four prediction columns:\n",
    "    - predicted_bedroom\n",
    "    - predicted_bathroom\n",
    "    - tokens_used\n",
    "    - time_seconds\n",
    "    \"\"\"\n",
    "\n",
    "    merged_records = []\n",
    "    # Determine how many rows to iterate over\n",
    "    length = len(df_GPT)\n",
    "    if same_results:\n",
    "        length = len(same_results)\n",
    "    for j in range(length):\n",
    "        i = j\n",
    "        # Determine actual index from same_results or fallback to j\n",
    "        if same_results:\n",
    "            i = same_results['i'][j]\n",
    "        \n",
    "        # Skip if qpid mismatch (sanity check)\n",
    "        if df_samples.data['qpid'][i] != df_GPT['qpid'][i]:\n",
    "            continue  # skip mismatches\n",
    "\n",
    "        # Convert original row to dict (drop last two columns)\n",
    "        row = df_samples.data.iloc[i,:-2].to_dict()\n",
    "\n",
    "        row['predicted_bathroom'] = df_GPT['bathrooms'][i]\n",
    "        row['predicted_bedroom'] = df_GPT['bedrooms'][i]\n",
    "        row['tokens_used'] = df_GPT['tokens_used'][i]\n",
    "        row['time_seconds'] = df_GPT['time_seconds'][i]\n",
    "\n",
    "        merged_records.append(row)\n",
    "\n",
    "    return pd.DataFrame(merged_records)\n",
    "\n",
    "'''\n",
    "## You can save the data with correct bathroom/bedroom data using the following codes\n",
    "same_all = pd.DataFrame(acc_all)\n",
    "same_bath = pd.DataFrame(acc_bath)\n",
    "same_bed = pd.DataFrame(acc_bed)\n",
    "\n",
    "results_all = merge_predictions_with_samples(df_samples, df_GPT, same_all)\n",
    "results_bath =  merge_predictions_with_samples(df_samples, df_GPT, same_bath)\n",
    "results_bed =  merge_predictions_with_samples(df_samples, df_GPT, same_bed)\n",
    "\n",
    "results_all.to_excel(f'./results/results_all_n{n}.xlsx', index=False)\n",
    "results_bath.to_excel(f'./results/results_bath_n{n}.xlsx', index=False)\n",
    "results_bed.to_excel(f'./results/results_bed_n{n}.xlsx', index=False)\n",
    "print(f'Save files successfully')\n",
    "'''\n",
    "\n",
    "# The following is to save all the data for the further comparison\n",
    "data_all = merge_predictions_with_samples(df_samples, df_GPT, same_results=None)\n",
    "data_all.to_excel(f'./results/data_all_n{n}.xlsx', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Excel is successfully modified\n"
     ]
    }
   ],
   "source": [
    "# This part is to modify the width of the Excel cell to make it more clear\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "'''\n",
    "excel_paths = [\n",
    "    f'./results/results_all_n{n}.xlsx',\n",
    "    f'./results/results_bath_n{n}.xlsx',\n",
    "    f'./results/results_bed_n{n}.xlsx',\n",
    "]\n",
    "'''\n",
    "excel_paths = [\n",
    "    f'./results/data_all_n{n}.xlsx'\n",
    "]\n",
    "\n",
    "for excel_path in excel_paths:\n",
    "    wb = load_workbook(excel_path)\n",
    "    sheet_name = wb.sheetnames[0]  # ‚úÖ use the first sheet name (or change as needed)\n",
    "    ws = wb[sheet_name] if sheet_name else wb.active\n",
    "\n",
    "    for col in ws.columns:\n",
    "        max_len = 0\n",
    "        col_letter = get_column_letter(col[0].column)\n",
    "        for cell in col:\n",
    "            try:\n",
    "                val_len = len(str(cell.value))\n",
    "                max_len = max(max_len, val_len)\n",
    "            except:\n",
    "                pass\n",
    "        ws.column_dimensions[col_letter].width = max_len * 1.2\n",
    "\n",
    "    wb.save(excel_path)\n",
    "    print('The Excel is successfully modified')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_property",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
